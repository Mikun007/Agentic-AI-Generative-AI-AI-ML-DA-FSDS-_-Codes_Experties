{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865af8be-1e0b-4b40-be21-9a640c94f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import re #regular expression\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479acd04-fded-49c6-8193-a616b217436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The cute cats are playing in the garden!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a9c85-8266-4cce-9cc5-ee042f9a43ac",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3196f87-4c3e-49be-9371-4ee199856335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cute cats are playing in the garden\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94216a04-1503-4bfc-8850-910aa60152d0",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844d61a4-677e-4166-838e-75071599b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cute', 'cats', 'are', 'playing', 'in', 'the', 'garden']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe350c7-ed94-460b-9819-8a6924bf8358",
   "metadata": {},
   "source": [
    "### Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccefd379-caf4-4c5b-af89-045d4e861d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute', 'cats', 'playing', 'garden']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d541d-3407-46c1-a800-2aac073c617b",
   "metadata": {},
   "source": [
    "### Stemming: finding the root words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66e90f03-4d60-4980-850f-daa4fe88347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute', 'cat', 'play', 'garden']\n",
      "['cut', 'cat', 'play', 'gard']\n",
      "['cute', 'cat', 'play', 'garden']\n"
     ]
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "print([porter.stem(word) for word in filtered_tokens])\n",
    "print([lancaster.stem(word) for word in filtered_tokens])\n",
    "print([snowball.stem(word) for word in filtered_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644d37e-8875-4193-80d9-614269c4374e",
   "metadata": {},
   "source": [
    "### Lemmatization: Grammer root word finding more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b69dc07d-5b8b-404c-9d72-80b51f72f1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute', 'cat', 'playing', 'garden']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67791679-19e8-4c45-b26c-19deb62c2876",
   "metadata": {},
   "source": [
    "### Lemmatization using POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d000ff50-2665-4c32-aead-259f24818acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pos_tag(filtered_tokens)\n",
    "\n",
    "lemmatized = []\n",
    "\n",
    "for word, tag in pos_tags:\n",
    "    if tag.startswith(\"V\"):\n",
    "        lemmatized.append(lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "\n",
    "    else:\n",
    "        lemmatized.append(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9fa6668-8364-4172-9f6d-a6dbfdc8d2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute', 'cat', 'play', 'garden']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed97dd88-0064-4b5f-9b37-e6b5a3563358",
   "metadata": {},
   "source": [
    "### POS tagging (Part of Speach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cbb99ed-e922-467e-bd72-21cfe9f89d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('cute', 'NN'), ('cats', 'NNS'), ('are', 'VBP'), ('playing', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('garden', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "pos = pos_tag(tokens)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be557cc7-2a3d-4997-9ac4-4dbb1ac88b73",
   "metadata": {},
   "source": [
    "### Chunking (Noun Phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afcb1b95-8ee5-4edc-9bb3-d5285d7ff1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT cute/NN cats/NNS)\n",
      "  are/VBP\n",
      "  playing/VBG\n",
      "  in/IN\n",
      "  (NP the/DT garden/NN))\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN.*>+}\"\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "tree = chunk_parser.parse(pos)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e2b84-1d16-4734-b311-2b38e5fae075",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8ba8080-d284-4af0-915d-68dbf8cd0568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  the/DT\n",
      "  cute/NN\n",
      "  cats/NNS\n",
      "  are/VBP\n",
      "  playing/VBG\n",
      "  in/IN\n",
      "  the/DT\n",
      "  garden/NN)\n"
     ]
    }
   ],
   "source": [
    "ner_tree = ne_chunk(pos)\n",
    "print(ner_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "565f99dc-0881-48c8-ae47-701361d04e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Virat/NNP)\n",
      "  (ORGANIZATION Kohli/NNP)\n",
      "  plays/VBZ\n",
      "  cricket/NN\n",
      "  for/IN\n",
      "  (GPE India/NNP))\n"
     ]
    }
   ],
   "source": [
    "## Example 2\n",
    "text2 = \"Virat Kohli plays cricket for India\"\n",
    "tokens2 = word_tokenize(text2)\n",
    "pos2 = pos_tag(tokens2)\n",
    "ner = ne_chunk(pos2)\n",
    "print(ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094877a-837c-4973-9273-b23c9f728556",
   "metadata": {},
   "source": [
    "### Bag of Words( BoW )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91ea90f9-406b-499e-8317-5ab2e33ce8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'cute' 'dog' 'smart']\n",
      "[[1 2 0 0]\n",
      " [0 1 1 0]\n",
      " [0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"cute cute cat\",\n",
    "    \"cute dog\",\n",
    "    \"smart dog\"\n",
    "]\n",
    "\n",
    "bow = CountVectorizer()\n",
    "x_bow = bow.fit_transform(corpus)\n",
    "\n",
    "print(bow.get_feature_names_out())\n",
    "print(x_bow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625356f3-38ba-4cd7-b7ba-a470b3bc5950",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71201383-7e7a-4446-8237-9b9b0c6d8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'cute' 'dog' 'smart']\n",
      "[[0.54935123 0.83559154 0.         0.        ]\n",
      " [0.         0.70710678 0.70710678 0.        ]\n",
      " [0.         0.         0.60534851 0.79596054]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(corpus)\n",
    "\n",
    "print(tfidf.get_feature_names_out())\n",
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14f89f-a499-44da-b172-a57ff938d259",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "437fe54a-3303-4d9b-8a35-218d24dac5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0724545e-03  4.7286271e-04  1.0206699e-02  1.8018546e-02\n",
      " -1.8605899e-02 -1.4233618e-02  1.2917745e-02  1.7945977e-02\n",
      " -1.0030856e-02 -7.5267432e-03  1.4761009e-02 -3.0669428e-03\n",
      " -9.0732267e-03  1.3108104e-02 -9.7203208e-03 -3.6320353e-03\n",
      "  5.7531595e-03  1.9837476e-03 -1.6570430e-02 -1.8897636e-02\n",
      "  1.4623532e-02  1.0140524e-02  1.3515387e-02  1.5257311e-03\n",
      "  1.2701781e-02 -6.8107317e-03 -1.8928028e-03  1.1537147e-02\n",
      " -1.5043275e-02 -7.8722071e-03 -1.5023164e-02 -1.8600845e-03\n",
      "  1.9076237e-02 -1.4638334e-02 -4.6675373e-03 -3.8754821e-03\n",
      "  1.6154874e-02 -1.1861792e-02  9.0324880e-05 -9.5074680e-03\n",
      " -1.9207101e-02  1.0014586e-02 -1.7519170e-02 -8.7836506e-03\n",
      " -7.0199967e-05 -5.9236289e-04 -1.5322480e-02  1.9229487e-02\n",
      "  9.9641159e-03  1.8466286e-02]\n",
      "-0.0144752655\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    [\"cute\", \"cat\"],\n",
    "    [\"cute\", \"dog\"],\n",
    "    [\"smart\", \"cat\"]\n",
    "]\n",
    "\n",
    "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1)\n",
    "\n",
    "print(model.wv[\"cat\"])\n",
    "print(model.wv.similarity(\"cat\", \"dog\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179d78c-7653-496e-ba64-33577b180b5c",
   "metadata": {},
   "source": [
    "### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9539396-ade6-4282-b3b0-4d1c1b32c618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
